---
title: Monte Carlo方法 2
author: Yi LIU
date: '2021-07-28'
slug: monte-carlo-2
categories: 
  - Work
tags: 
  - Bayesian
  - Stats
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
bibliography: [../Refs.bib]
biblio-style: "apalike"
link-citations: true
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#简介introduction">简介(Introduction)</a></li>
<li><a href="#markov-chain">Markov chain</a></li>
<li><a href="#metropolis-hasting算法">Metropolis-Hasting算法</a></li>
<li><a href="#例子香蕉形状后验分布">例子：香蕉形状后验分布</a></li>
<li><a href="#小结">小结</a></li>
</ul>
</div>

<div id="简介introduction" class="section level2">
<h2>简介(Introduction)</h2>
<p>在Importance Sampling (IS)中，一个对于采样效率和采样结果可靠性的很重要的因素是如何选取替代分布概率<span class="math inline">\(q(\theta)\)</span>。这其中有很多因素需要考虑，比如<span class="math inline">\(q(\theta)\)</span>的取值范围是否涵盖了我们的目标概率分布<span class="math inline">\(p(\theta)\)</span>的取值范围，怎样可以使得采样的方差比较小。这些需要大量的关于<span class="math inline">\(p(\theta)\)</span>的知识和经验才能设计出合适的<span class="math inline">\(q(\theta)\)</span>。</p>
<p>那么有没有一种采样方法能减少这个选取过程中的工作量呢？答案是有的。下面我们就介绍这样一种方法：Markov Chain Monte Carlo (MCMC)。MCMC的基本想法是如果我们有一条Markov chain，如果它的稳态分布(stationary distribution)就是我们的目标分布，那么我们从这条Markov chain上生产足够多的达到稳态后的样本，那么我们就得到了目标函数的采样。</p>
<p>那么现在的问题是：怎样生成一条问题分布是目标分布的Markov chain？因为Markov chain的稳态分布完全由转移概率(transition probability)决定，那么这也就等价于设计Markov chain的转移概率分布，使得Markov chain的稳态分布就是我们的目标分布。幸运的是，这个问题可以用一个比较通用的算法解决。在介绍这个算法之前，我们先简单介绍一下Markov chain。</p>
</div>
<div id="markov-chain" class="section level2">
<h2>Markov chain</h2>
<p>Markov chain是一种随机过程，包含了一系列随机变量<span class="math inline">\(\Theta_1, \Theta_2, \dots\)</span>，它们满足如下关系：</p>
<p><span class="math display">\[ P(\Theta_{n+1} =\theta_{i_{n+1}} | \Theta_{n} = \theta_{i_{n}}, \dots, \Theta_1 = \theta_{i_1}) = P(\Theta_{n+1} =\theta_{i_{n+1}} | \Theta_{n} = \theta_{i_{n}}) \]</span></p>
<p>也就是说下一个状态的取值只和现在的状态取值有关。</p>
<p>因为我们的目标是稳态分布是目标分布的Markov chain，所以我们主要关注只有一个平稳分布的Markov chain。对于离散取值空间的Markov chain来说需要满足以下几个条件：</p>
<ol style="list-style-type: decimal">
<li>Irreducibile：通俗来说就是从任意一个状态出发，可以到达任何其他任何状态。直观上就是说不会有一个只进不出或者只出不进的区域。</li>
<li>Aperiodic：简单来说就是对于任意一个状态来说，在跑过足够多的预热步数之后，在每一步都有一定概率回到该状态。这一点是为了保证稳态分布的唯一性。</li>
</ol>
<p>关于这一点的证明需要用到Perron-Frobenius定理。具体的证明过程读者可以参考<a href="https://www.math.fsu.edu/~dmandel/Primers/Markov%20Chains%20and%20Stationary%20Distributions.pdf">这里</a>和<a href="https://stanford.edu/class/ee363/lectures/pf.pdf">这里</a>。对于连续状态空间，也有类似的证明，可以参考<a href="https://statistics.berkeley.edu/sites/default/files/tech-reports/501.pdf">这里</a>（PS:我没有看懂）</p>
</div>
<div id="metropolis-hasting算法" class="section level2">
<h2>Metropolis-Hasting算法</h2>
<p>Metropolis-Hasing算法的大意是我们有一个目标分布<span class="math inline">\(p(\theta)\)</span>，此外还有一个转移概率为<span class="math inline">\(q(\theta&#39;|\theta)\)</span>的稳态Markov chain <span class="math inline">\(m\)</span>。注意，目前<span class="math inline">\(q(\theta&#39;|\theta)\)</span>生成的Markov chain <span class="math inline">\(m\)</span>的稳态不是<span class="math inline">\(p(\theta)\)</span>。我们通过修改<span class="math inline">\(m\)</span>的转移概率<span class="math inline">\(q(\theta&#39;|\theta)\)</span>生成一个新的Markov chain <span class="math inline">\(m&#39;\)</span>，使得<span class="math inline">\(m&#39;\)</span>的稳态分布就是<span class="math inline">\(p(\theta)\)</span>。</p>
<p>具体算法如下：
1. 对于<span class="math inline">\(X_n = \theta_i\)</span>，生成<span class="math inline">\(\theta_j \sim q(\theta| \theta_i)\)</span>
2. 计算接受概率(acceptance probability): <span class="math inline">\(a(\theta_j|\theta_i) = \min(1, \frac{p(\theta_j)q(\theta_i|\theta_j))}{p(\theta_i)q(\theta_j|\theta_i)})\)</span>
3. 以概率<span class="math inline">\(a(\theta_j|\theta_i\)</span>接受新的样本<span class="math inline">\(X_{n+1} = \theta_j\)</span>，否则<span class="math inline">\(X_{n+1} = \theta_i\)</span></p>
<p>这里我们只证明目标分布<span class="math inline">\(p(\theta)\)</span>是上面的Markov chain的稳态分布，即满足细致平衡条件(detailed balance)。</p>
<p><span class="math display">\[
\begin{aligned}
\underbrace{a(\theta_j|\theta_i)q(\theta_j|\theta_i)}_{P(\theta_j|\theta_i)} p(\theta_i) =  &amp; \min(1, \frac{p(\theta_j)q(\theta_i|\theta_j))}{p(\theta_i)q(\theta_j|\theta_i)})q(\theta_j|\theta_i)p(\theta_i) \\
= &amp; \min (q(\theta_j|\theta_i)p(\theta_i), p(\theta_j)q(\theta_i|\theta_j))) \\
= &amp; \min(\frac{p(\theta_i)q(\theta_j|\theta_i))}{p(\theta_j)q(\theta_i|\theta_j)}, 1)q(\theta_i|\theta_j)p(\theta_j) \\
= &amp; \underbrace{a(\theta_i|\theta_j)q(\theta_i|\theta_j)}_{P(\theta_j|\theta_i)} p(\theta_j)
\end{aligned}
\]</span>
其中，我们使用了符号<span class="math inline">\(P(\theta_j|\theta_i)\)</span>来代表<span class="math inline">\(m&#39;\)</span>的转移概率。</p>
<p>有几点值得注意的：</p>
<ol style="list-style-type: decimal">
<li>对于MCMC来说，对于<span class="math inline">\(p(\theta)\)</span>并不需要归一化，因为只需要能够计算<span class="math inline">\(p(\theta)/p(\theta&#39;)\)</span>就可以。</li>
<li>MCMC必须要收敛到稳态分布才能提供可靠的采样样本，简单来说就是遍历了态空间。</li>
<li>对于MCMC来说，proposal distribution的选取对于采样效率十分重要。如果选取的不合适，会有两种可能导致采样效率过低。1）接受率很低，这会使得Markov chain在态空间里很少移动，经常停留在某些状态上；2）接受率很高，这可能是因为每次的proposal <span class="math inline">\(\theta_j\)</span>都很接近<span class="math inline">\(\theta_i\)</span>，也就是Markov chain每一步的步长都很短，也需要很长时间才能探索完整个态空间，达到稳态。</li>
</ol>
<p>上面的Metropolis-Hasting算法有一种特例：如果<span class="math inline">\(q(\theta_i|\theta_j) = q(\theta_j|\theta_i)\)</span>那么上面的接受概率就简化成了<span class="math inline">\(a(\theta_j|\theta_i) = \min(1, \frac{p(\theta_j)}{p(\theta_i)})\)</span>。这种特例称为Metropolis算法。我们下面的例子就是就是采用这种特殊算法。</p>
</div>
<div id="例子香蕉形状后验分布" class="section level2">
<h2>例子：香蕉形状后验分布</h2>
<p>这个例子来自<a href="https://zcrabbit.github.io/">张成老师</a>的<a href="https://zcrabbit.github.io/courses/btc-s21.html">Bayesian Theory and Computation</a>课程。考虑的是一个标准的贝叶斯模型：</p>
<ol style="list-style-type: decimal">
<li>先验(Prior)：<span class="math inline">\(\theta_1 \sim \mathcal{N}(0, 1)\)</span>，<span class="math inline">\(\theta_2 \sim \mathcal{N}(0, 1)\)</span></li>
<li>似然函数(Likelihood): <span class="math inline">\(p(y_i|\theta_1, \theta_2) \sim \mathcal{N} (\theta_1 + \theta_2^2, \sigma_y^2)\)</span>(<span class="math inline">\(\sigma_y=2\)</span>)</li>
<li>后验(Posterior): <span class="math inline">\(p(\theta_1, \theta_2| y_i) \propto \exp\left(-\frac{\theta_1^2 + \theta_2^2}{2}\right) \exp\left(-\frac{\sum_i (y_i - \theta_1 -\theta_2^2)^2}{2\sigma_y^2}\right)\)</span></li>
</ol>
<p>我们的目的是生成后验概率的采样，利有Metropolis算法，我们选取<span class="math inline">\(q(\theta&#39;|\theta) \sim \mathcal{N}(0, 0.15\mathbf{1})\)</span>。</p>
<p>我们先生成样本</p>
<pre class="python"><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
from functools import partial
from scipy.stats import multivariate_normal

np.random.seed(1234)
sigma_y = 2
sample_size = 30
theta1 = np.random.randn()
theta2 = np.random.randn()

print(f&quot;Theta1: {theta1}&quot;)</code></pre>
<pre><code>## Theta1: 0.47143516373249306</code></pre>
<pre class="python"><code>print(f&quot;Theta2: {theta2}&quot;)</code></pre>
<pre><code>## Theta2: -1.1909756947064645</code></pre>
<pre class="python"><code>y_samples = theta1 + theta2**2 + sigma_y * np.random.randn(sample_size)
plt.plot(np.arange(sample_size), y_samples, &#39;o&#39;, alpha=0.5);
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>下面我们写出没有归一化的后验概率</p>
<pre class="python"><code>def unnormalized_posterior(theta, y, sigma_y):
    theta1 = theta[0]
    theta2 = theta[1]
    return 100000*np.exp(-0.5*(theta1**2 + theta2**2)) * np.exp(-0.5*np.sum((y - theta1 - theta2**2)**2) / (sigma_y**2))</code></pre>
<p>上面的函数里，我们没有归一化，同时也在返回的时候乘了一个因子100000。这个并不影响采样本身，因为我们需要的是后验概率的比值，所以常数因子没有影响。之所以这么做是为了在后面可视化的时候，可以比较好的画出后验概率的contour。</p>
<p>我们再为后面方便定义一个函数</p>
<pre class="python"><code>theta_posterior = partial(unnormalized_posterior, y=y_samples, sigma_y=sigma_y)</code></pre>
<p>我们可以画出后验概率的分布</p>
<pre><code>## &lt;matplotlib.contour.QuadContourSet object at 0x7f8ec03f1588&gt;</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>我们再定义一个正太分布的类，以便后面使用。</p>
<pre class="python"><code>class normal_distribution:
    def __init__(self, mu, cov):
        self.mu = mu
        self.cov = cov
        
    def pdf(self, x):
        return multivariate_normal.pdf(x, mean=self.mu, cov=self.cov)
    
    def __call__(self, num_samples):
        return multivariate_normal.rvs(mean=self.mu, cov=self.cov, size=num_samples)</code></pre>
<p>下面我们可以定义MCMC采样类了</p>
<pre class="python"><code>class SimMCMCSampler:
    def __init__(self, target_prob, delta_proposal_dist: normal_distribution):
        self.target_prob = target_prob
        self.delta_proposal_dist = delta_proposal_dist
        self.step = 0
        # self.accepted_proposal = 0
        
    def one_step_mc(self, current_state: np.array):
        proposal_state = current_state + self.delta_proposal_dist(1)
        accept_rate = np.min([1, self.target_prob(proposal_state) / self.target_prob(current_state)])
        rand_u = np.random.rand()
        if rand_u &lt;= accept_rate:
            return proposal_state, 1
        return current_state, 0
    
    def run_mc(self, start_state: np.array, num_steps=1000):
        state_shape = start_state.shape[0]
        samples = np.zeros((num_steps+1, state_shape))
        samples[0] = start_state
        self.proposal_acceptance = np.zeros(num_steps)
        for step in range(num_steps):
            next_state, accept = self.one_step_mc(samples[step])
            samples[step+1] = next_state
            self.step += 1
            # self.accepted_proposal += accept
            self.proposal_acceptance[step] = accept
        return samples</code></pre>
<p>MCMC的主要算法就在上面的<code>one_step_mc</code>函数里了。下面我们来进行模拟采样。首先，我们采用一个均值为0，方差为<code>0.15**2</code>的高斯分布作为proposal distribtuion</p>
<pre class="python"><code>medium_proposal_dist = normal_distribution([0, 0], [[0.15**2, 0], [0, 0.15**2]])
medium_sampler = SimMCMCSampler(theta_posterior, medium_proposal_dist)
medium_samples = medium_sampler.run_mc(np.array([-0.5, 1.5]), 10000)

plt.contourf(theta1_2d, theta2_2d, posterior_2d, levels=100, cmap=&quot;Blues&quot;);
plt.plot(medium_samples[:, 0], medium_samples[:, 1], &#39;o&#39;, color=&quot;orange&quot;, alpha=0.1, markersize=2);
plt.xlim(-2.0, 2.0);
plt.ylim(-2.0, 2.0);
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>从上面的采样结果来看，经过10000步的采样，基本得到了比较符合后验概率的结果。下面我们看看不同的proposal distribution会对采样结果有什么影响。先看一个方差较小的高斯分布的采样效果</p>
<pre class="python"><code>small_proposal_dist = normal_distribution([0, 0], [[0.01**2, 0], [0, 0.01**2]])
small_sampler = SimMCMCSampler(theta_posterior, small_proposal_dist)
small_samples = small_sampler.run_mc(np.array([-0.5, 1.5]), 10000)

plt.contourf(theta1_2d, theta2_2d, posterior_2d, levels=100, cmap=&quot;Blues&quot;);
plt.plot(small_samples[:, 0], small_samples[:, 1], &#39;o&#39;, color=&quot;orange&quot;, alpha=0.1, markersize=2);
plt.xlim(-2.0, 2.0);
plt.ylim(-2.0, 2.0);
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-1.png" width="672" />
从上面的结果可以看到，这次采样只探索了参数空间很小的一部分，远没有收敛到稳态。</p>
<p>然后是方差较大的高斯分布的采样结果</p>
<pre class="python"><code>large_proposal_dist = normal_distribution([0, 0], [[0.5**2, 0], [0, 0.5**2]])
large_sampler = SimMCMCSampler(theta_posterior, large_proposal_dist)
large_samples = large_sampler.run_mc(np.array([-0.5, 1.5]), 10000)

plt.contourf(theta1_2d, theta2_2d, posterior_2d, levels=100, cmap=&quot;Blues&quot;);
plt.plot(large_samples[:, 0], large_samples[:, 1], &#39;o&#39;, color=&quot;orange&quot;, alpha=0.1, markersize=2);
plt.xlim(-2.0, 2.0);
plt.ylim(-2.0, 2.0);
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-10-1.png" width="672" />
从上面的结果可以看到，此时对于参数空间的探索范围比较大，但是点会稀疏一点。</p>
<p>在上面三个采样中，不同的就是proposal distribution的方差不同。可以看到，如果proposal distribution方差过小（<code>small_samples</code>），那么Markov chain在<span class="math inline">\(\theta\)</span>空间中每一步移动都很慢，采样效率很低。如果方差过大（<code>large_samples</code>），那么又会有很多的采样不被接受（参见下图）
<img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div id="小结" class="section level1">
<h1>小结</h1>
<p>本文简单介绍了一种不那么需要人工设计的Monte Carlo方法，Markov chain Monte Carlo方法，还给出了算法描述以及一个简单的实现。这种算法的一个优点是几乎是半自动的，只需要一个简单的Markov chain的<code>proposal distribution</code>就可以生成我们需要的概率分布的采样。但是我们模拟结果来看，MCMC的采样效率还是和它用到的<code>proposal distribution</code>有关，如何选取以便提高采样效率并平衡达到稳态的速度（或者说遍历参数空间），是一个很需要技巧和经验的问题。在后续文章中，我们会介绍提高MCMC采样效率的方法。</p>
</div>
